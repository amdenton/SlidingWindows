{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the LandCover Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_label(label_raster_path):\n",
    "    with rasterio.open(label_raster_path) as label:\n",
    "        label_arr=label.read(1)\n",
    "    return label_arr\n",
    "label_arr=read_label('Rasters/cdl_new.tif')\n",
    "def read_raster_data(raster_data_path):\n",
    "    with rasterio.open(raster_data_path) as rast_data:\n",
    "        rast_data_arr=rast_data.read()\n",
    "        rast_data_arr=rast_data_arr.reshape((rast_data_arr.shape[1],rast_data_arr.shape[2],rast_data_arr.shape[0]))\n",
    "    return rast_data_arr\n",
    "rast_data=read_raster_data('Rasters/new1.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4373, 4021, 5), (4373, 4021))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding corner points \n",
    "def find_corners(cdl_arr):\n",
    "    corners=[(0,0)] # the left top corner the begining of the image.\n",
    "    fixed=corners[-1][0]\n",
    "    for i in range(cdl_arr.shape[1]):\n",
    "        if cdl_arr[fixed][i]==0:\n",
    "            corners.append((fixed,i-1)) # right top\n",
    "            break\n",
    "    fixed=corners[-1][1]\n",
    "    for i in range(cdl_arr.shape[0]):\n",
    "        if cdl_arr[i][fixed]==0:\n",
    "            corners.append((i-1,fixed)) #right bottom\n",
    "            corners.append((i-1,0)) #left bottom\n",
    "            break\n",
    "    return corners\n",
    "\n",
    "find_corners(label_arr)\n",
    "rast_data.shape,label_arr.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1922.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def wh_max(label_arr,patch_size):\n",
    "    corners=find_corners(label_arr)\n",
    "    xy_min=min(min(rast_data.shape[:2]),min(label_arr.shape)) # the right top y coordinate or the right bottom x coordinate\n",
    "    width= int(xy_min/patch_size)*patch_size\n",
    "    return width\n",
    "max_width=wh_max(label_arr,64)\n",
    "(max_width/64*max_width/64)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(1985, 0), (3904, 3904)], [(0, 0), (1984, 1984)], [(0, 1985), (1984, 3904)]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_test_quaters(label_arr,patch_size):\n",
    "    max_width=wh_max(label_arr,patch_size)\n",
    "    max_height=max_width\n",
    "    train_quater=[(int(max_width/2)+1,0),(max_height-patch_size,max_width-patch_size)]\n",
    "    validate_quater=[(0,0),(int(max_height/2),int(max_width/2))]\n",
    "    test_quater=[(0,int(max_width/2+1)),(int(max_height/2),max_width-patch_size)]\n",
    "    return [train_quater,validate_quater,test_quater]\n",
    "train_test_quaters(label_arr,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 4308011, 5: 7576650, 6: 26478, 23: 1575780, 28: 324, 36: 4140, 37: 44142, 41: 1206504, 42: 14496, 61: 864, 111: 12912, 121: 685973, 122: 66384, 123: 25704, 124: 3168, 131: 936, 141: 143922, 142: 396, 152: 36, 176: 201858, 190: 37866, 195: 276128}\n",
      "re_mapping {0: 1, 1: 5, 2: 6, 3: 23, 4: 28, 5: 36, 6: 37, 7: 41, 8: 42, 9: 61, 10: 111, 11: 121, 12: 122, 13: 123, 14: 124, 15: 131, 16: 141, 17: 142, 18: 152, 19: 176, 20: 190, 21: 195}\n",
      "mapping {1: 0, 5: 1, 6: 2, 23: 3, 28: 4, 36: 5, 37: 6, 41: 7, 42: 8, 61: 9, 111: 10, 121: 11, 122: 12, 123: 13, 124: 14, 131: 15, 141: 16, 142: 17, 152: 18, 176: 19, 190: 20, 195: 21}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def label_encode_dict(label_arr):\n",
    "    classes,counts=np.unique(label_arr,return_counts=True)\n",
    "    class_count=dict(zip(classes,counts))\n",
    "    print( class_count)\n",
    "    plt.bar( class_count.keys(),class_count.values(), width=1.0, color='g')\n",
    "    plt.show\n",
    "    one_hot_dict={value:key for key, value in enumerate(classes)}\n",
    "    return one_hot_dict, class_count\n",
    "mapping,class_count=label_encode_dict(label_arr[:3968+64,:3968+64])\n",
    "plt.bar( class_count.keys(),class_count.values(), width=10.0, color='g')\n",
    "re_mapping={value:key for key,value in mapping.items()}\n",
    "print(\"re_mapping\",re_mapping)\n",
    "print(\"mapping\",mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weight = class_weight.compute_class_weight('balanced'\n",
    "                                               ,np.unique(label_arr[:3968+64,:3968+64])\n",
    "                                               ,label_arr[:3968+64,:3968+64].ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 22 artists>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar( class_count.keys(),class_weight, width=10.0, color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(label_arr[:3968+64,:3968+64]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 22)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_labels_patch(label_arr,x_cord,y_cord,patch_size):\n",
    "    label_encode=np.zeros((patch_size,patch_size,len(mapping.keys())))\n",
    "    for i in range(patch_size):\n",
    "        for j in range(patch_size):\n",
    "            label_encode[i][j][mapping[label_arr[x_cord+i][y_cord+j]]]=1\n",
    "    return label_encode\n",
    "temp=read_labels_patch(label_arr,0,0,64)\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_data_patch(rast_data,x_cord,y_cord,patch_size):\n",
    "    #data_patch=np.zeros((patch_size,patch_size,rast_data.shape[2]))\n",
    "    data_patch=rast_data[x_cord:x_cord+patch_size,y_cord:y_cord+patch_size]\n",
    "#     for i in range(patch_size):\n",
    "#         for j in range(patch_size):\n",
    "#             data_patch[i][j]=rast_data[x_cord+i][y_cord+j]\n",
    "    return data_patch\n",
    "read_data_patch(rast_data,0,0,64).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Parameters\n",
    "patch_size=64\n",
    "num_classes=22\n",
    "batch_size=64\n",
    "num_channels=5\n",
    "train_steps=1922\n",
    "val_steps=1000\n",
    "test_steps=1000\n",
    "num_epochs=100\n",
    "quarters=train_test_quaters(label_arr,patch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4373, 4021)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xml.dom import minidom\n",
    "def normalize_xml(rast_data,xml_file):\n",
    "    xml_doc=minidom.parse(xml_file)\n",
    "    nodes=xml_doc.getElementsByTagName(\"re:bandSpecificMetadata\")\n",
    "    coeffs = {}\n",
    "    for node in nodes:\n",
    "        bn = node.getElementsByTagName(\"re:bandNumber\")[0].firstChild.data\n",
    "        if bn in ['1', '2', '3', '4']:\n",
    "            i = int(bn)\n",
    "            value = node.getElementsByTagName(\"re:radiometricScaleFactor\")[0].firstChild.data\n",
    "            coeffs[i] = float(value)\n",
    "    #rast_data=[rast_data[i]*coeffs[i+1] for i in range(4)]\n",
    "    for i in range(4):\n",
    "        rast_data[i]=rast_data[i]*coeffs[i+1]\n",
    "        \n",
    "        #norm_bands.append(band)\n",
    "    return rast_data\n",
    "xml_file='1460322_2014-08-13_RE2_3A_305154_metadata.xml'\n",
    "norm_bands=normalize_xml(rast_data,xml_file)\n",
    "norm_bands[:,:,0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding a layer of Regression b/n red and nir using the sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_pixel_array(b1_in,b2_in):\n",
    "    \n",
    "    width,height=b1_in.shape\n",
    "    \n",
    "    b11_in=b1_in * b1_in\n",
    "    b22_in=b2_in*b2_in\n",
    "    b12_in=b1_in*b2_in\n",
    "    '''\n",
    "     #flatten the arrarys \n",
    "    b1_in_flat=b1_in.flatten()\n",
    "    b2_in_flat=b2_in.flatten()\n",
    "    b11_in_flat=b11_in.flatten()\n",
    "    b22_in_flat=b22_in.flatten()\n",
    "    b12_in_flat=b12_in.flatten()\n",
    "    '''\n",
    "    b_in_list =list((b1_in,b2_in, b11_in,b22_in,b12_in)) \n",
    "    return b_in_list,width,height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sliding_window(band_in_list,width,height,w_size,method):\n",
    "    \n",
    "    delta=w_size//2\n",
    "    col_extent_old = width - delta + 1\n",
    "    row_extent = width - delta + 1\n",
    "    col_extent = height - delta + 1\n",
    "    \n",
    "    #select the block indecies\n",
    "    selector = lambda a: np.lib.stride_tricks.as_strided(a, shape=(row_extent,col_extent,delta,delta), strides=a.strides+a.strides)\n",
    "    # Get offsetted indices across the height and width of input array\n",
    "    #output_index_set = np.arange(row_extent)[:,None]*col_extent_old + np.arange(col_extent)\n",
    "    #full_selector = np.lib.stride_tricks.as_strided(band_in_list[0], shape=(row_extent,col_extent,delta,delta), strides=band_in_list[0].strides+band_in_list[0].strides)\n",
    "    \n",
    "    #implement the selector on the arrays\n",
    "    '''\n",
    "    b1_in_selc=np.take(band_in_list[0],selector(band_in_list[0]).astype(float))\n",
    "    b2_in_selc=np.take(band_in_list[1],selector(band_in_list[1]).astype(float))\n",
    "    b11_in_selc=np.take(band_in_list[2],selector(band_in_list[2]).astype(float))\n",
    "    b22_in_selc=np.take(band_in_list[3],selector(band_in_list[3]).astype(float))\n",
    "    b12_in_selc=np.take(band_in_list[4],selector(band_in_list[4]).astype(float))\n",
    "    '''\n",
    "    band_out_list=[]\n",
    "    if method=='sum':\n",
    "        for band in band_in_list:\n",
    "            band_out_list.append(np.sum(selector(band),axis=(2,3)))\n",
    "    elif method=='mean':\n",
    "        for band in band_in_list:\n",
    "            band_out_list.append(np.mean(selector(band),axis=(2,3)))\n",
    "    elif method=='max':\n",
    "        for band in band_in_list:\n",
    "            band_out_list.append(np.max(selector(band),axis=(2,3)))\n",
    "    elif method=='min':\n",
    "        for band in band_in_list:\n",
    "            band_out_list.append(np.min(selector(band),axis=(2,3)))\n",
    "    return band_out_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def windowRegression(band_out_list,w):\n",
    "    #x_diff = x_max-w+1\n",
    "    #y_diff = y_max-w+1\n",
    "    size = band_out_list[0].size\n",
    "    count = w*w\n",
    "    m = np.empty(size)\n",
    "    \n",
    "    if any(band.size!=size for band in band_out_list):\n",
    "        print(size)\n",
    "        #print(band.size)\n",
    "        raise ValueError('In windowRegression: x_max and/or y_max inconsistent with length of a, b, aa, and / or ab')\n",
    "\n",
    "    numerator = count * band_out_list[-1] - band_out_list[0]* band_out_list[1]\n",
    "    denominator = count * band_out_list[2] - band_out_list[0] * band_out_list[0]\n",
    "    m = numerator/denominator\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4373, 4021)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4370, 4018)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_size=8\n",
    "red_band,nir_band=norm_bands[:,:,2],norm_bands[:,:,3]\n",
    "print(red_band.shape)\n",
    "bands_in,w,h=read_pixel_array(red_band,nir_band)\n",
    "bands_out=sliding_window(bands_in,w,h,w_size,'sum')\n",
    "reg_band=windowRegression(bands_out,w_size)\n",
    "reg_band.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4370, 4018, 5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_bands[:-3,:-3,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4370, 4018, 6)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rast_data=np.dstack((norm_bands[:-3,:-3,:],reg_band))\n",
    "rast_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0 for train 1 for val and 2 for test\n",
    "def data_read(rast_data,label_data,patch_size,batch_size,mode=0):\n",
    "    quater=quarters[mode]\n",
    "    while True:\n",
    "        data,label=[],[]\n",
    "        for i in range(batch_size):\n",
    "            x_cord=np.random.randint(quater[0][0],quater[1][0])\n",
    "            y_cord=np.random.randint(quater[0][1],quater[1][1])\n",
    "            data.append(read_data_patch(rast_data,x_cord,y_cord,patch_size))\n",
    "            label.append(read_labels_patch(label_arr,x_cord,y_cord,patch_size))\n",
    "        data=np.array(data)\n",
    "        label=np.array(label)\n",
    "        yield data,label\n",
    "\n",
    "#train_data,train_label=train_data.reshape(-1,num_channels),train_label.reshape(-1,num_classes)\n",
    "#print(train_data.shape,train_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 64, 5) (64, 64, 64, 22)\n"
     ]
    }
   ],
   "source": [
    "generator_train=data_read(norm_bands,label_arr,patch_size,batch_size,0)\n",
    "for train_data,train_label in generator_train:\n",
    "    print(train_data.shape,train_label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 64, 5) (64, 64, 64, 22)\n"
     ]
    }
   ],
   "source": [
    "generator_val=data_read(norm_bands,label_arr,patch_size,batch_size,1)\n",
    "for test_data,test_label in generator_val:\n",
    "    print(test_data.shape,test_label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 64, 5) (64, 64, 64, 22)\n"
     ]
    }
   ],
   "source": [
    "generator_test=data_read(norm_bands,label_arr,patch_size,batch_size,2)\n",
    "for test_data,test_label in generator_test:\n",
    "    print(test_data.shape,test_label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,LearningRateScheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "def f_measure(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    f_measure: Harmonic mean of specificity and sensitivity, shall be used to calculate score batch wise\n",
    "    during training\n",
    "    **for binary classification only**\n",
    "    @param\n",
    "    y_true: Tensor of actual labels \n",
    "    y_pred: Tensor of predicted labels \n",
    "    @returns \n",
    "    f_measure score for a batch \n",
    "    \"\"\"\n",
    "    def specificity(y_true, y_pred):\n",
    "        \"\"\"Compute the confusion matrix for a set of predictions.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        y_pred   : predicted values for a batch if samples (must be binary: 0 or 1)\n",
    "        y_true   : correct values for the set of samples used (must be binary: 0 or 1)\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        out : the specificity\n",
    "        \"\"\"\n",
    "        neg_y_true = 1 - y_true\n",
    "        neg_y_pred = 1 - y_pred\n",
    "        fp = K.sum(neg_y_true * y_pred)\n",
    "        tn = K.sum(neg_y_true * neg_y_pred)\n",
    "        \n",
    "        specificity = tn / (tn + fp + K.epsilon())\n",
    "        return specificity\n",
    "    \n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "        \n",
    "        Only computes a batch-wise average of recall.\n",
    "        \n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "    \n",
    "    specificity = specificity(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((specificity * recall)/(specificity + recall + K.epsilon()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    \"\"\"Computes the F score.\n",
    "     The F1 score is harmonic mean of precision and recall.\n",
    "     it is computed as a batch-wise average.\n",
    "     This is can be used for multi-label classification. \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "         Only computes a batch-wise average of precision.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    f1_score = 2 * (p * r) / (p + r + K.epsilon())\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "batch_normalization_3_input (In (None, 64, 64, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 64, 64, 5)    0           batch_normalization_3_input[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 64, 64, 5)    0           batch_normalization_3_input[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 64, 64, 22)   79242       lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Concatenate)      (None, 64, 64, 22)   0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "==================================================================================================\n",
      "Total params: 79,242\n",
      "Trainable params: 79,040\n",
      "Non-trainable params: 202\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(patch_size,patch_size,num_channels)))\n",
    "model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(num_classes, (3, 3), padding='same'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate Adam optimizer\n",
    "opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
    "\n",
    "parallel_model = multi_gpu_model(model,gpus=2, cpu_merge=False)\n",
    "# Let's train the model using Adam\n",
    "parallel_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy',f_measure])\n",
    "parallel_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_loss', patience=5),\n",
    "             ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "Epoch 1/100\n",
      "1921/1922 [============================>.] - ETA: 0s - loss: 95.1742 - acc: 0.4574 - f_measure: 0.1804WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "1922/1922 [==============================] - 586s 305ms/step - loss: 95.1801 - acc: 0.4574 - f_measure: 0.1804 - val_loss: 100.6784 - val_acc: 0.4680 - val_f_measure: 0.0781\n",
      "Epoch 2/100\n",
      "1921/1922 [============================>.] - ETA: 0s - loss: 93.7613 - acc: 0.4611 - f_measure: 0.1494WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "1922/1922 [==============================] - 596s 310ms/step - loss: 93.7590 - acc: 0.4611 - f_measure: 0.1494 - val_loss: 103.1402 - val_acc: 0.4302 - val_f_measure: 0.0667\n",
      "Epoch 3/100\n",
      "1921/1922 [============================>.] - ETA: 0s - loss: 93.7284 - acc: 0.4604 - f_measure: 0.1401WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "1922/1922 [==============================] - 587s 305ms/step - loss: 93.7333 - acc: 0.4604 - f_measure: 0.1401 - val_loss: 100.2618 - val_acc: 0.4669 - val_f_measure: 0.0387\n",
      "Epoch 4/100\n",
      "1921/1922 [============================>.] - ETA: 0s - loss: 93.3056 - acc: 0.4627 - f_measure: 0.1552WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "1922/1922 [==============================] - 595s 309ms/step - loss: 93.3053 - acc: 0.4628 - f_measure: 0.1553 - val_loss: 101.5284 - val_acc: 0.4397 - val_f_measure: 0.0385\n",
      "Epoch 5/100\n",
      "1921/1922 [============================>.] - ETA: 0s - loss: 93.2228 - acc: 0.4610 - f_measure: 0.1438WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "1922/1922 [==============================] - 589s 306ms/step - loss: 93.2235 - acc: 0.4610 - f_measure: 0.1439 - val_loss: 101.7455 - val_acc: 0.4718 - val_f_measure: 0.1212\n",
      "Epoch 6/100\n",
      "1921/1922 [============================>.] - ETA: 0s - loss: 92.8397 - acc: 0.4614 - f_measure: 0.1423WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "1922/1922 [==============================] - 586s 305ms/step - loss: 92.8436 - acc: 0.4614 - f_measure: 0.1423 - val_loss: 103.4172 - val_acc: 0.4190 - val_f_measure: 0.0529\n",
      "Epoch 7/100\n",
      "1921/1922 [============================>.] - ETA: 0s - loss: 92.8987 - acc: 0.4608 - f_measure: 0.1460WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "1922/1922 [==============================] - 597s 311ms/step - loss: 92.8938 - acc: 0.4608 - f_measure: 0.1460 - val_loss: 102.4056 - val_acc: 0.4272 - val_f_measure: 0.0495\n",
      "Epoch 8/100\n",
      "1921/1922 [============================>.] - ETA: 0s - loss: 92.6064 - acc: 0.4629 - f_measure: 0.1649WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "1922/1922 [==============================] - 595s 310ms/step - loss: 92.6097 - acc: 0.4629 - f_measure: 0.1649 - val_loss: 102.1220 - val_acc: 0.4667 - val_f_measure: 0.1303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2f44093438>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_model.fit_generator(generator_train,steps_per_epoch=train_steps,\n",
    "                   epochs=num_epochs, callbacks=callbacks, validation_data=generator_val,\n",
    "                    validation_steps=val_steps,class_weight=class_weight,\n",
    "                    max_queue_size=10, workers=8,\n",
    "                    use_multiprocessing=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 187s 187ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[106.64414714813232, 0.48072733306884763, 0.1248791414834559]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_model.evaluate_generator(generator_test,steps=test_steps,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 937/1000 [===========================>..] - ETA: 29s"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "predicted=np.zeros((max_width,max_width))\n",
    "#for i in range(0,max_width,patch_size):\n",
    "predict=parallel_model.predict_generator(generator_test,steps=test_steps,verbose=1)\n",
    "for key in remapping: \n",
    "    predict[predict==key]=remapping[key]\n",
    "    \n",
    "img=Image.fromarray(predict)\n",
    "img.save('predicted.png')\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unet(pretrained_weights = None,input_shape=(patch_size,patch_size,num_channels)):\n",
    "    inputs = Input(input_shape)\n",
    "    #inputs = BatchNormalization()(inputs)\n",
    "    conv1 = Conv2D(64, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(512, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512,(2,2), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(512, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, (2,2), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, (2,2), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, (2,2), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv10 = Conv2D(num_classes, (3, 3), activation = 'softmax',padding = 'same')(conv9)\n",
    "\n",
    "    model = Model(inputs, conv10)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'categorical_crossentropy', metrics=['accuracy',f_measure])\n",
    "    \n",
    "    print(model.summary())\n",
    "\n",
    "    if(pretrained_weights):\n",
    "        model.load_weights(pretrained_weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_loss', patience=5),\n",
    "             ModelCheckpoint(filepath='unet_membrane.hdf5', monitor='val_loss', save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 64, 64, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 64, 64, 64)   2944        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 64)   36928       conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 32, 32, 64)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 128)  73856       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 128)  147584      conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 128)  0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 16, 256)  295168      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 256)  590080      conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 256)    0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 8, 8, 512)    1180160     max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 8, 8, 512)    2359808     conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 8, 8, 512)    0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 4, 4, 512)    0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 4, 4, 1024)   4719616     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 4, 4, 1024)   9438208     conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 4, 4, 1024)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 8, 8, 1024)   0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 8, 8, 512)    2097664     up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 8, 8, 1024)   0           dropout[0][0]                    \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 8, 8, 512)    4719104     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 8, 8, 512)    2359808     conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 16, 16, 512)  0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 256)  524544      up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 16, 16, 512)  0           conv2d_5[0][0]                   \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 256)  1179904     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 256)  590080      conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 32, 32, 256)  0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 128)  131200      up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 256)  0           conv2d_3[0][0]                   \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 128)  295040      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 32, 32, 128)  147584      conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 64, 64, 128)  0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 64, 64, 64)   32832       up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 64, 64, 128)  0           conv2d_1[0][0]                   \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 64, 64, 64)   73792       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 64, 64, 64)   36928       conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 64, 64, 2)    1154        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 64, 64, 22)   418         conv2d_22[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 31,034,404\n",
      "Trainable params: 31,034,404\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "Epoch 1/100\n",
      "1921/1922 [============================>.] - ETA: 0s - loss: 189.9623 - acc: 0.4608 - f_measure: 6.5928e-06WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "1922/1922 [==============================] - 1479s 769ms/step - loss: 189.9577 - acc: 0.4608 - f_measure: 6.5893e-06 - val_loss: 181.4081 - val_acc: 0.4692 - val_f_measure: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1921/1922 [============================>.] - ETA: 0s - loss: 173.5760 - acc: 0.4619 - f_measure: 0.0000e+00WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "1922/1922 [==============================] - 1457s 758ms/step - loss: 173.5717 - acc: 0.4619 - f_measure: 0.0000e+00 - val_loss: 166.7265 - val_acc: 0.4676 - val_f_measure: 0.0000e+00\n",
      "Epoch 3/100\n",
      "1921/1922 [============================>.] - ETA: 0s - loss: 159.2666 - acc: 0.4619 - f_measure: 0.0000e+00WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "1922/1922 [==============================] - 1457s 758ms/step - loss: 159.2635 - acc: 0.4619 - f_measure: 0.0000e+00 - val_loss: 153.5618 - val_acc: 0.4686 - val_f_measure: 0.0000e+00\n",
      "Epoch 4/100\n",
      "1921/1922 [============================>.] - ETA: 0s - loss: 146.5211 - acc: 0.4625 - f_measure: 0.0000e+00WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "1922/1922 [==============================] - 1458s 758ms/step - loss: 146.5191 - acc: 0.4625 - f_measure: 0.0000e+00 - val_loss: 142.2859 - val_acc: 0.4662 - val_f_measure: 0.0000e+00\n",
      "Epoch 5/100\n",
      "1921/1922 [============================>.] - ETA: 0s - loss: 135.3931 - acc: 0.4615 - f_measure: 0.0000e+00WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "1922/1922 [==============================] - 1463s 761ms/step - loss: 135.3893 - acc: 0.4615 - f_measure: 0.0000e+00 - val_loss: 132.2672 - val_acc: 0.4671 - val_f_measure: 0.0000e+00\n",
      "Epoch 6/100\n",
      "1921/1922 [============================>.] - ETA: 0s - loss: 125.8001 - acc: 0.4630 - f_measure: 0.0000e+00WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "1922/1922 [==============================] - 1443s 751ms/step - loss: 125.8007 - acc: 0.4630 - f_measure: 0.0000e+00 - val_loss: 124.3975 - val_acc: 0.4653 - val_f_measure: 0.0000e+00\n",
      "Epoch 7/100\n",
      "1921/1922 [============================>.] - ETA: 0s - loss: 118.2639 - acc: 0.4613 - f_measure: 0.0000e+00WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "1922/1922 [==============================] - 1455s 757ms/step - loss: 118.2641 - acc: 0.4613 - f_measure: 0.0000e+00 - val_loss: 117.8822 - val_acc: 0.4690 - val_f_measure: 0.0000e+00\n",
      "Epoch 8/100\n",
      "1921/1922 [============================>.] - ETA: 0s - loss: 111.7768 - acc: 0.4615 - f_measure: 0.0000e+00WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "1922/1922 [==============================] - 1452s 756ms/step - loss: 111.7770 - acc: 0.4615 - f_measure: 0.0000e+00 - val_loss: 112.9583 - val_acc: 0.4684 - val_f_measure: 0.0000e+00\n",
      "Epoch 9/100\n",
      "1921/1922 [============================>.] - ETA: 0s - loss: 107.2094 - acc: 0.4619 - f_measure: 0.0000e+00WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "1922/1922 [==============================] - 1457s 758ms/step - loss: 107.2098 - acc: 0.4619 - f_measure: 0.0000e+00 - val_loss: 108.7844 - val_acc: 0.4713 - val_f_measure: 0.0000e+00\n",
      "Epoch 10/100\n",
      "1921/1922 [============================>.] - ETA: 0s - loss: 103.7502 - acc: 0.4611 - f_measure: 0.0000e+00WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "1922/1922 [==============================] - 1456s 757ms/step - loss: 103.7538 - acc: 0.4611 - f_measure: 0.0000e+00 - val_loss: 106.4406 - val_acc: 0.4661 - val_f_measure: 0.0000e+00\n",
      "Epoch 11/100\n",
      "1921/1922 [============================>.] - ETA: 0s - loss: 101.0576 - acc: 0.4631 - f_measure: 0.0000e+00WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "1922/1922 [==============================] - 1458s 759ms/step - loss: 101.0627 - acc: 0.4631 - f_measure: 0.0000e+00 - val_loss: 104.1527 - val_acc: 0.4697 - val_f_measure: 0.0000e+00\n",
      "Epoch 12/100\n",
      "1921/1922 [============================>.] - ETA: 0s - loss: 99.0338 - acc: 0.4636 - f_measure: 0.0000e+00WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "1922/1922 [==============================] - 1457s 758ms/step - loss: 99.0343 - acc: 0.4636 - f_measure: 0.0000e+00 - val_loss: 102.5481 - val_acc: 0.4702 - val_f_measure: 0.0000e+00\n",
      "Epoch 13/100\n",
      "1921/1922 [============================>.] - ETA: 0s - loss: 97.5622 - acc: 0.4651 - f_measure: 0.0000e+00WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "1922/1922 [==============================] - 1461s 760ms/step - loss: 97.5621 - acc: 0.4651 - f_measure: 0.0000e+00 - val_loss: 101.8906 - val_acc: 0.4676 - val_f_measure: 0.0000e+00\n",
      "Epoch 14/100\n",
      "1921/1922 [============================>.] - ETA: 0s - loss: 97.1072 - acc: 0.4611 - f_measure: 0.0000e+00WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "1922/1922 [==============================] - 1455s 757ms/step - loss: 97.1103 - acc: 0.4611 - f_measure: 0.0000e+00 - val_loss: 100.8217 - val_acc: 0.4692 - val_f_measure: 0.0000e+00\n",
      "Epoch 15/100\n",
      "1921/1922 [============================>.] - ETA: 0s - loss: 96.2799 - acc: 0.4624 - f_measure: 0.0000e+00WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "1922/1922 [==============================] - 1441s 750ms/step - loss: 96.2746 - acc: 0.4625 - f_measure: 0.0000e+00 - val_loss: 100.4054 - val_acc: 0.4681 - val_f_measure: 0.0000e+00\n",
      "Epoch 16/100\n",
      "1921/1922 [============================>.] - ETA: 0s - loss: 95.6688 - acc: 0.4621 - f_measure: 0.0000e+00WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "1922/1922 [==============================] - 1456s 758ms/step - loss: 95.6663 - acc: 0.4622 - f_measure: 0.0000e+00 - val_loss: 100.1252 - val_acc: 0.4671 - val_f_measure: 0.0000e+00\n",
      "Epoch 17/100\n",
      "1921/1922 [============================>.] - ETA: 0s - loss: 95.3373 - acc: 0.4601 - f_measure: 0.0000e+00WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "1922/1922 [==============================] - 1458s 758ms/step - loss: 95.3393 - acc: 0.4601 - f_measure: 0.0000e+00 - val_loss: 99.7843 - val_acc: 0.4693 - val_f_measure: 0.0000e+00\n",
      "Epoch 18/100\n",
      "1921/1922 [============================>.] - ETA: 0s - loss: 95.2377 - acc: 0.4605 - f_measure: 0.0000e+00WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "1922/1922 [==============================] - 1456s 758ms/step - loss: 95.2377 - acc: 0.4604 - f_measure: 0.0000e+00 - val_loss: 99.3912 - val_acc: 0.4716 - val_f_measure: 0.0000e+00\n",
      "Epoch 19/100\n",
      "1921/1922 [============================>.] - ETA: 0s - loss: 94.9378 - acc: 0.4611 - f_measure: 0.0000e+00WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "1922/1922 [==============================] - 1458s 759ms/step - loss: 94.9438 - acc: 0.4611 - f_measure: 0.0000e+00 - val_loss: 99.3887 - val_acc: 0.4692 - val_f_measure: 0.0000e+00\n",
      "Epoch 20/100\n",
      "1921/1922 [============================>.] - ETA: 0s - loss: 94.8004 - acc: 0.4613 - f_measure: 0.0000e+00WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "1922/1922 [==============================] - 1457s 758ms/step - loss: 94.8057 - acc: 0.4613 - f_measure: 0.0000e+00 - val_loss: 99.3102 - val_acc: 0.4681 - val_f_measure: 0.0000e+00\n",
      "Epoch 21/100\n",
      "1921/1922 [============================>.] - ETA: 0s - loss: 94.3725 - acc: 0.4611 - f_measure: 0.0000e+00WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "1922/1922 [==============================] - 1462s 761ms/step - loss: 94.3696 - acc: 0.4611 - f_measure: 0.0000e+00 - val_loss: 99.0709 - val_acc: 0.4682 - val_f_measure: 0.0000e+00\n",
      "Epoch 22/100\n",
      "1921/1922 [============================>.] - ETA: 0s - loss: 94.4137 - acc: 0.4623 - f_measure: 0.0000e+00WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "1922/1922 [==============================] - 1461s 760ms/step - loss: 94.4198 - acc: 0.4623 - f_measure: 0.0000e+00 - val_loss: 98.8802 - val_acc: 0.4694 - val_f_measure: 0.0000e+00\n",
      "Epoch 23/100\n",
      "1921/1922 [============================>.] - ETA: 0s - loss: 94.2007 - acc: 0.4609 - f_measure: 0.0000e+00WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "1922/1922 [==============================] - 1459s 759ms/step - loss: 94.2020 - acc: 0.4609 - f_measure: 0.0000e+00 - val_loss: 98.9276 - val_acc: 0.4676 - val_f_measure: 0.0000e+00\n",
      "Epoch 24/100\n",
      "1921/1922 [============================>.] - ETA: 0s - loss: 94.2820 - acc: 0.4626 - f_measure: 0.0000e+00WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "1922/1922 [==============================] - 1455s 757ms/step - loss: 94.2832 - acc: 0.4626 - f_measure: 0.0000e+00 - val_loss: 99.1414 - val_acc: 0.4680 - val_f_measure: 0.0000e+00\n",
      "Epoch 25/100\n",
      "1921/1922 [============================>.] - ETA: 0s - loss: 93.9562 - acc: 0.4609 - f_measure: 0.0000e+00WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "1922/1922 [==============================] - 1476s 768ms/step - loss: 93.9507 - acc: 0.4609 - f_measure: 0.0000e+00 - val_loss: 98.9754 - val_acc: 0.4710 - val_f_measure: 0.0000e+00\n",
      "Epoch 26/100\n",
      "1921/1922 [============================>.] - ETA: 0s - loss: 94.1649 - acc: 0.4623 - f_measure: 0.0000e+00WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "1922/1922 [==============================] - 1474s 767ms/step - loss: 94.1644 - acc: 0.4623 - f_measure: 0.0000e+00 - val_loss: 98.8790 - val_acc: 0.4702 - val_f_measure: 0.0000e+00\n",
      "Epoch 27/100\n",
      "1921/1922 [============================>.] - ETA: 0s - loss: 93.9670 - acc: 0.4627 - f_measure: 0.0000e+00WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "1922/1922 [==============================] - 1480s 770ms/step - loss: 93.9691 - acc: 0.4627 - f_measure: 0.0000e+00 - val_loss: 99.1594 - val_acc: 0.4643 - val_f_measure: 0.0000e+00\n",
      "Epoch 28/100\n",
      "1921/1922 [============================>.] - ETA: 0s - loss: 94.0278 - acc: 0.4625 - f_measure: 0.0000e+00WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "1922/1922 [==============================] - 1485s 772ms/step - loss: 94.0284 - acc: 0.4624 - f_measure: 0.0000e+00 - val_loss: 99.2563 - val_acc: 0.4690 - val_f_measure: 0.0000e+00\n",
      "Epoch 29/100\n",
      "1921/1922 [============================>.] - ETA: 0s - loss: 93.9341 - acc: 0.4606 - f_measure: 0.0000e+00WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "1922/1922 [==============================] - 1441s 750ms/step - loss: 93.9406 - acc: 0.4606 - f_measure: 0.0000e+00 - val_loss: 99.4342 - val_acc: 0.4687 - val_f_measure: 0.0000e+00\n",
      "Epoch 30/100\n",
      "1921/1922 [============================>.] - ETA: 0s - loss: 94.1576 - acc: 0.4612 - f_measure: 0.0000e+00WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "1922/1922 [==============================] - 1434s 746ms/step - loss: 94.1603 - acc: 0.4612 - f_measure: 0.0000e+00 - val_loss: 99.0156 - val_acc: 0.4684 - val_f_measure: 0.0000e+00\n",
      "Epoch 31/100\n",
      "1921/1922 [============================>.] - ETA: 0s - loss: 93.9432 - acc: 0.4621 - f_measure: 0.0000e+00WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "1922/1922 [==============================] - 1433s 746ms/step - loss: 93.9434 - acc: 0.4621 - f_measure: 0.0000e+00 - val_loss: 99.3125 - val_acc: 0.4690 - val_f_measure: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3fe8461438>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=unet()\n",
    "\n",
    "model.fit_generator(generator_train,steps_per_epoch=train_steps,\n",
    "                   epochs=num_epochs, callbacks=callbacks, validation_data=generator_val,\n",
    "                    validation_steps=val_steps,class_weight=class_weight,\n",
    "                    max_queue_size=10, workers=8,\n",
    "                    use_multiprocessing=True, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 204s 204ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[103.32558403015136, 0.48488019180297853, 0.0]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(generator_test,steps=test_steps,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# UNET for Sat Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unet_sat(n_classes=num_classes, im_sz=patch_size, n_channels=num_channels, n_filters_start=32, growth_factor=2, upconv=True,\n",
    "               class_weights=class_weight):\n",
    "    droprate=0.25\n",
    "    n_filters = n_filters_start\n",
    "    inputs = Input((im_sz, im_sz, n_channels))\n",
    "    inputs = BatchNormalization()(inputs)\n",
    "    conv1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    #pool1 = Dropout(droprate)(pool1)\n",
    "\n",
    "    n_filters *= growth_factor\n",
    "    pool1 = BatchNormalization()(pool1)\n",
    "    conv2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    pool2 = Dropout(droprate)(pool2)\n",
    "\n",
    "    n_filters *= growth_factor\n",
    "    pool2 = BatchNormalization()(pool2)\n",
    "    conv3 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    pool3 = Dropout(droprate)(pool3)\n",
    "\n",
    "    n_filters *= growth_factor\n",
    "    pool3 = BatchNormalization()(pool3)\n",
    "    conv4_0 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4_0 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv4_0)\n",
    "    pool4_1 = MaxPooling2D(pool_size=(2, 2))(conv4_0)\n",
    "    pool4_1 = Dropout(droprate)(pool4_1)\n",
    "\n",
    "    n_filters *= growth_factor\n",
    "    pool4_1 = BatchNormalization()(pool4_1)\n",
    "    conv4_1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool4_1)\n",
    "    conv4_1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv4_1)\n",
    "    pool4_2 = MaxPooling2D(pool_size=(2, 2))(conv4_1)\n",
    "    pool4_2 = Dropout(droprate)(pool4_2)\n",
    "\n",
    "    n_filters *= growth_factor\n",
    "    conv5 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool4_2)\n",
    "    conv5 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    n_filters //= growth_factor\n",
    "    if upconv:\n",
    "        up6_1 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv5), conv4_1])\n",
    "    else:\n",
    "        up6_1 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv4_1])\n",
    "    up6_1 = BatchNormalization()(up6_1)\n",
    "    conv6_1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up6_1)\n",
    "    conv6_1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv6_1)\n",
    "    conv6_1 = Dropout(droprate)(conv6_1)\n",
    "\n",
    "    n_filters //= growth_factor\n",
    "    if upconv:\n",
    "        up6_2 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv6_1), conv4_0])\n",
    "    else:\n",
    "        up6_2 = concatenate([UpSampling2D(size=(2, 2))(conv6_1), conv4_0])\n",
    "    up6_2 = BatchNormalization()(up6_2)\n",
    "    conv6_2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up6_2)\n",
    "    conv6_2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv6_2)\n",
    "    conv6_2 = Dropout(droprate)(conv6_2)\n",
    "\n",
    "    n_filters //= growth_factor\n",
    "    if upconv:\n",
    "        up7 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv6_2), conv3])\n",
    "    else:\n",
    "        up7 = concatenate([UpSampling2D(size=(2, 2))(conv6_2), conv3])\n",
    "    up7 = BatchNormalization()(up7)\n",
    "    conv7 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv7)\n",
    "    conv7 = Dropout(droprate)(conv7)\n",
    "\n",
    "    n_filters //= growth_factor\n",
    "    if upconv:\n",
    "        up8 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv7), conv2])\n",
    "    else:\n",
    "        up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), conv2])\n",
    "    up8 = BatchNormalization()(up8)\n",
    "    conv8 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv8)\n",
    "    conv8 = Dropout(droprate)(conv8)\n",
    "\n",
    "    n_filters //= growth_factor\n",
    "    if upconv:\n",
    "        up9 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv8), conv1])\n",
    "    else:\n",
    "        up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), conv1])\n",
    "    conv9 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "    conv10 = Conv2D(n_classes, (1, 1), activation='softmax')(conv9)\n",
    "\n",
    "    model = Model(inputs, conv10)\n",
    "    print(model.summary())\n",
    "\n",
    "    def weighted_binary_crossentropy(y_true, y_pred):\n",
    "        class_loglosses = K.mean(K.binary_crossentropy(y_true, y_pred), axis=[0, 1, 2])\n",
    "        return K.sum(class_loglosses * K.constant(class_weights))\n",
    "    \n",
    "    parallel_model = multi_gpu_model(model,gpus=2, cpu_merge=False)\n",
    "    parallel_model.compile(optimizer=Adam(), loss='categorical_crossentropy',metrics=['accuracy',f_measure])\n",
    "    return parallel_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_loss', patience=5),\n",
    "             ModelCheckpoint(filepath='unet_membrane.hdf5', monitor='val_loss', save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute '_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-6ebea84690ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munet_sat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m model.fit_generator(generator_train,steps_per_epoch=train_steps,\n\u001b[1;32m      4\u001b[0m                    \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-ee7f42f09f02>\u001b[0m in \u001b[0;36munet_sat\u001b[0;34m(n_classes, im_sz, n_channels, n_filters_start, growth_factor, upconv, class_weights)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mconv10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf-gpu3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0;31m# Create a cache for iterator get_next op.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_get_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWeakKeyDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf-gpu3/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m         'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[1;32m     79\u001b[0m       \u001b[0;31m# Graph network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m       \u001b[0;31m# Subclassed network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf-gpu3/lib/python3.6/site-packages/tensorflow/python/training/checkpointable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m       \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf-gpu3/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[1;32m    216\u001b[0m                         \u001b[0;34m'Note that input tensors are '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                         \u001b[0;34m'instantiated via `tensor = tf.layers.Input(shape)`.\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m                         'The tensor that caused the issue was: ' + str(x.name))\n\u001b[0m\u001b[1;32m    219\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_history'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf-gpu3/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mname\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    222\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Model' object has no attribute '_name'"
     ]
    }
   ],
   "source": [
    "model=unet_sat()\n",
    "\n",
    "model.fit_generator(generator_train,steps_per_epoch=train_steps,\n",
    "                   epochs=num_epochs, callbacks=callbacks, validation_data=generator_val,\n",
    "                    validation_steps=val_steps,class_weight=class_weight,\n",
    "                    max_queue_size=10, workers=8,\n",
    "                    use_multiprocessing=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 94s 94ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[322.99516000366214, 0.48488114166259766, 0.6360743516087533]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(generator_test,steps=test_steps,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_placeholder(batch_size,width,height,n_channel,n_class):\n",
    "    X=tf.placeholder(tf.float32,shape=(None,width*height,n_channel))\n",
    "    y=tf.placeholder(tf.float32,shape=(None,n_class))\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def intialize_parameters():\n",
    "    tf.set_random_seed(1)\n",
    "    W1=tf.get_variable(\"W1\",[1,4,5,8],initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    W2=tf.get_variable(\"W2\",[1,2,8,16],initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    parameters={\"W1\":W1,\n",
    "                \"W2\":W2}\n",
    "    return parameters\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X,parameters):\n",
    "    W1=parameters['W1']\n",
    "    W2=parameters['W2']\n",
    "    Z1=tf.nn.conv2d(X,W1,strides=[1,1,1,1],padding='SAME')\n",
    "    A1=tf.nn.relu(Z1)\n",
    "    P1=tf.nn.max_pool(A1,ksize=[1,8,8,1],padding='SAME')\n",
    "    Z2=tf.nn.conv2d(P1,W2,strides=[1,1,1,1],padding='SAME')\n",
    "    A2=tf.nn.relu(Z2)\n",
    "    P2=tf.nnmax_pool(A2,ksize=[1,4,4,1],padding='SAME')\n",
    "    P2=tf.contrib.layers.flatten(P2)\n",
    "    Z3=tf.contrib.layers.fully_connected(P2,num_outputs=23,activation_fn=None)\n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    np.random.seed(1)\n",
    "    X,Y=create_placeholder(32,32,5,24)\n",
    "    parameters=initialize_parameters()\n",
    "    Z3=forward_propagation(X,parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
